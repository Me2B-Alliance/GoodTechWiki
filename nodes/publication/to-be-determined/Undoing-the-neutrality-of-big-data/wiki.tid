created:1582526115771
modified:1582526115771
title:Undoing the neutrality of big data
type:text/vnd.tiddlywiki
audience:
authors.editors:
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
name:Undoing the neutrality of big data
publication.type:[[TO BE DETERMINED]]
purpose:
sector:
sponsoring.org:
tags:[[enabling connected learning]]
tech.focus:
tmap.edges:{}
tmap.id:69424902-f1c3-4e4e-b3c7-8bb35502cdc8
url:https://datasociety.net/output/undoing-the-neutrality-of-big-data/
version.or.edition:
volume.frequency:
working.group:

    The mythology surrounding “big data” rests on the notion that technical systems can increase efficiency and decrease bias. Such “neutral” systems are supposedly good for implementing legal logic because, like these systems, law relies on binaries in decision-making, removing the gray and fuzzy from the equation. The problem with this formulation is that efficiency is not necessarily desirable, bias is baked into the data sets and reified technically as well as through interpretation, and legal binaries are neither socially productive nor logically sound.

D&S founder danah boyd responds to Margaret Hu’s work in Big Data Blacklisting with supportive arguments that further Hu’s assertions. boyd discusses how procedure and efficiency make algorithmic decision-making so attractive to policymakers and bureaucrats yet flawed systems in place do not make data neutral and in fact ‘blacklists purposefully distance decision-makers from the humanity of those who are being labeled’.
