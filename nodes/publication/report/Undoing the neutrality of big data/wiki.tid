audience:
authors.editors:
created:1582678071975
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
modified:1582678071975
name:Undoing the neutrality of big data
publication.type:report
purpose:
sector:
sponsoring.org:
tags:[object Set]
tech.focus:
tiddler.classification:node
title:Undoing the neutrality of big data
tmap.edges:{}
tmap.id:1fc69a08-db61-475c-8e2e-0158ce4e163a
type:text/vnd.tiddlywiki
url:https://datasociety.net/output/undoing-the-neutrality-of-big-data/
version.or.edition:
volume.frequency:
working.group:

    The mythology surrounding “big data” rests on the notion that technical systems can increase efficiency and decrease bias. Such “neutral” systems are supposedly good for implementing legal logic because, like these systems, law relies on binaries in decision-making, removing the gray and fuzzy from the equation. The problem with this formulation is that efficiency is not necessarily desirable, bias is baked into the data sets and reified technically as well as through interpretation, and legal binaries are neither socially productive nor logically sound.

D&S founder danah boyd responds to Margaret Hu’s work in Big Data Blacklisting with supportive arguments that further Hu’s assertions. boyd discusses how procedure and efficiency make algorithmic decision-making so attractive to policymakers and bureaucrats yet flawed systems in place do not make data neutral and in fact ‘blacklists purposefully distance decision-makers from the humanity of those who are being labeled’.


