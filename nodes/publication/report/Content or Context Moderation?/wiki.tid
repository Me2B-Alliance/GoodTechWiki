audience:
authors.editors:[object Set]
created:1582678071974
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
modified:1582678071974
name:Content or Context Moderation?
publication.type:report
purpose:
sector:
sponsoring.org:
tags:[object Set]
tech.focus:
tiddler.classification:node
title:Content or Context Moderation?
tmap.edges:{}
tmap.id:9d53b443-7042-4505-a8ed-5465443fb68b
type:text/vnd.tiddlywiki
url:https://datasociety.net/output/content-or-context-moderation/
version.or.edition:
volume.frequency:
working.group:

n Content or Context Moderation?, Data & Society Affiliate Robyn Caplan draws from interviews with representatives at 10 major digital platforms to identify three content moderation strategies: artisanal, community-reliant, and industrial.

“Public oversight,” writes Caplan, “needs to incorporate not only the context of speech, but the organizational dynamics of platforms, to understand where new rules should be developed (for types of content) and where more resources are necessary.”

This report provides fresh insights for those developing content moderation policy and regulation by illustrating how leading companies’ missions, business models, and team sizes influence their approaches. Along the way, the report teases out the emergent challenges and tensions these actors face in balancing context and consistency.

