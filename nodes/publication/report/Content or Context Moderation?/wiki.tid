audience:
authors.editors:[[robyn caplan]]
created:1582720003601
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
modified:1582720003601
name:Content or Context Moderation?
publication.type:report
purpose:
sector:
sponsoring.org:
tags:[[algorithms and publics]]
tech.focus:
tiddler.classification:node
title:Content or Context Moderation?
tmap.edges:{}
tmap.id:b3a02cd1-5f21-452f-8539-5c0d1106897c
type:text/vnd.tiddlywiki
url:https://datasociety.net/output/content-or-context-moderation/
version.or.edition:
volume.frequency:
working.group:

n Content or Context Moderation?, Data & Society Affiliate Robyn Caplan draws from interviews with representatives at 10 major digital platforms to identify three content moderation strategies: artisanal, community-reliant, and industrial.

“Public oversight,” writes Caplan, “needs to incorporate not only the context of speech, but the organizational dynamics of platforms, to understand where new rules should be developed (for types of content) and where more resources are necessary.”

This report provides fresh insights for those developing content moderation policy and regulation by illustrating how leading companies’ missions, business models, and team sizes influence their approaches. Along the way, the report teases out the emergent challenges and tensions these actors face in balancing context and consistency.

