audience:
authors.editors:[object Set]
created:1582678071974
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
modified:1582678071974
name:Questions about Google autocompl
publication.type:report
purpose:
sector:
sponsoring.org:
tags:[object Set]
tech.focus:
tiddler.classification:node
title:Questions about Google autocompl
tmap.edges:{}
tmap.id:07ca0285-7720-4779-8335-a56a6be3a43d
type:text/vnd.tiddlywiki
url:https://datasociety.net/output/questions-about-google-autocompl/
version.or.edition:
volume.frequency:
working.group:

    What the journalists from SourceFed may have stumbled upon was not an instance in which search results were intentionally being manipulated in favor of a candidate, but how algorithms can reflect complex jurisdictional issues and international policies that can, in turn, govern content.

Points/spheres: D&S researcher Robyn Caplan asks: What drives Google’s policy of “not show[ing] a predicted query that is offensive or disparaging when displayed in conjunction with a person’s name?”


