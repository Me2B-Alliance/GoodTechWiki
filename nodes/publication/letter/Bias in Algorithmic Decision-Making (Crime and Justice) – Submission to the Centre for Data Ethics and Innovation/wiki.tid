audience:
authors.editors:
created:1582678071977
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
modified:1582678071977
name:Bias in Algorithmic Decision-Making (Crime and Justice) – Submission to the Centre for Data Ethics and Innovation
publication.type:letter
purpose:
sector:government
sponsoring.org:
tags:[object Set]
tech.focus:
tiddler.classification:node
title:Bias in Algorithmic Decision-Making (Crime and Justice) – Submission to the Centre for Data Ethics and Innovation
tmap.edges:{}
tmap.id:2de9e738-d520-4531-b2fd-67e1362d64a0
type:text/vnd.tiddlywiki
url:https://bigbrotherwatch.org.uk/wp-content/uploads/2019/06/Big-Brother-Watch-submission-to-the-Centre-for-Data-Ethics-and-Innovation-Bias-in-Algorithmic-Decision-Making-Crime-and-Justice-June-2019.pdf
version.or.edition:
volume.frequency:
working.group:

We   welcome   the   opportunity to   submit   evidence   to   the   Centre   for   Data   Ethics   and Innovation’sreview on bias in algorithmic decision-making.This  submission  will  focus  on  use  of  predictive  algorithms  in  both  policing  and  judicial decision-making.    New    technology    and    automated    systems,    encompassing    artificial intelligence, machine learningand big data analyticsare being used ever more widely in the criminal  justice  system.  These  are  being  used  to  predict  communities  to  target  with greater police  resources;  to  assess  individuals’risk  of  committing  crimes  in  the  future;  to  identify suspects in public places; and to supportpolice investigations.However,  these  new  systems  have  evidenced  some  extremely  concerning  biases.  There  are significant problems with the data being used to build and train these models, while some of those  building  the  models  have  shownlittle  regard  for  data  protection  or  human  rights.  This has  resulted  in  biased  and  discriminatory decisionsthat  are  in  large  part  automated,  with serious implications for the fairness of criminal justice. The protections afforded to individuals subject  to  these  biased,  unfair  or  unjust decisions  are  minimal.  Many  will  never  even  be aware they have been subject to such an automated decision.


