audience:
authors.editors:
created:1582678071977
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
modified:1582678071977
name:Big Brother Watch’s submission to The Law Society’s ‘Technology and the Law’ Policy Commission
publication.type:letter
purpose:
sector:government
sponsoring.org:
tags:[object Set]
tech.focus:
tiddler.classification:node
title:Big Brother Watch’s submission to The Law Society’s ‘Technology and the Law’ Policy Commission
tmap.edges:{}
tmap.id:acade3f3-a655-49f9-96a7-d6ea02082362
type:text/vnd.tiddlywiki
url:https://bigbrotherwatch.org.uk/wp-content/uploads/2019/02/Big-Brother-Watch-written-evidence-on-algorithms-in-the-justice-system-for-the-Law-Societys-Technology-and-the-Law-Policy-Commission-Feb-2019.pdf
version.or.edition:
volume.frequency:
working.group:

In this short submission, we focus on Durham Police’s use of the ‘Harm Assessment Risk Tool’(HART).   HART   is   an   artificially   intelligent   algorithmic   tool   used   to   make   recidivism   riskassessments about suspects and inform prosecution decisions. It was developed by DurhamPolice in conjunction with academics and has been in use since 2017. The AI risk predictions guide decisions as to whether a suspect should be charged or releasedonto the ‘Checkpoint’ rehabilitation programme. Moderate risk’ suspects are informed that ifthey successfully complete the Checkpoint programme they will not receive a criminal convictionWe focus on this tool because it is one of the most significant examples of algorithms in thejustice system in the UK, and was the topic of an investigation by Big Brother Watch in 2018. Webelieve that Durham Police’s creation and use of HART exemplifies many of the risks associatedwith rapid application of algorithms in the justice system: risks of discrimination, privacyintrusion, de facto automated decision making and profiling, as well as erosion of trust in lawenforcement.

